{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this iteration, I ran similar tests from the previous iteration. \n",
    "### However, I will focus more on the final approach to this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roo2=\"C:\\\\Users\\\\xyche\\\\Documents\\\\Parsons_Grad\\\\Fall2019\\\\ML\\\\EnronTraining\\\\test2\\\\cash-m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for directory, subdirectory, filenames in  os.walk(Roo2):\n",
    "#     print(directory, subdirectory, len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from email.parser import Parser\n",
    "\n",
    "file_to_read = \"C:\\\\Users\\\\xyche\\\\Documents\\\\Parsons_Grad\\\\Fall2019\\\\ML\\\\EnronTraining\\\\test2\\\\cash-m\\\\all_documents\\\\1_\"\n",
    "\n",
    "with open(file_to_read, \"r\") as f:\n",
    "    data = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To:  david.oxley@enron.com\n",
      "\n",
      " From:  michelle.cash@enron.com\n",
      "\n",
      " Subject:  Re: Triple Lutz Employee Matters\n"
     ]
    }
   ],
   "source": [
    "email = Parser().parsestr(data)\n",
    "\n",
    "print(\"\\nTo: \" , email['to'])\n",
    "print(\"\\n From: \" , email['from'])\n",
    "\n",
    "print(\"\\n Subject: \" , email['subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\n \\n Body: \" , email.get_payload())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdir = \"C:\\\\Users\\\\xyche\\\\Documents\\\\Parsons_Grad\\\\Fall2019\\\\ML\\\\EnronTraining\\\\test2\\\\cash-m\\\\inbox\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    " from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_analyse(inputfile, to_email_list, from_email_list, email_body):\n",
    "    with open(inputfile, \"r\") as f:\n",
    "        data = f.read()\n",
    " \n",
    "    if email['to']:\n",
    "        email_to = email['to']\n",
    "        email_to = email_to.replace(\"\\n\", \"\")\n",
    "        email_to = email_to.replace(\"\\t\", \"\")\n",
    "        email_to = email_to.replace(\" \", \"\")\n",
    "\n",
    "        email_to = email_to.split(\",\")\n",
    "\n",
    "        for email_to_1 in email_to:\n",
    "            to_email_list.append(email_to_1)\n",
    "\n",
    "    from_email_list.append(email['from'])\n",
    "\n",
    "    email_body.append(email.get_payload())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_email_list = []\n",
    "from_email_list = []\n",
    "email_body = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory, subdirectory, filenames in  os.walk(textdir):\n",
    "    for filename in filenames:\n",
    "        email_analyse(os.path.join(directory, filename), to_email_list, from_email_list, email_body )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"email_body.txt\", \"w\") as f:\n",
    "    for email_bod in email_body:\n",
    "        if email_bod:\n",
    "            f.write(email_bod)\n",
    "            f.write(\"\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"email_body.txt\", \"r\") as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_words = data.split( )\n",
    "# print(body_words,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "import re\n",
    "corpus = data\n",
    "text=''\n",
    "for word in re.findall(r'[a-zA-Z]+', corpus):\n",
    "    text += word + ' '\n",
    "    txt = text.strip()\n",
    "type(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stemmed = stemmer.stem(txt)\n",
    "# print(stemmed,10)\n",
    "type(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = stemmed.split(' ')\n",
    "# print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close()>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f= open(\"string.txt\",\"w+\")\n",
    "# f.write(stemmed)\n",
    "# f.close\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type('email_body.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type('string.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigram - word prediction\n",
    "\n",
    "####  inspired by Mohd Sanad Zaki Rizvi (https://gist.github.com/mohdsanadzakirizvi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import bigrams, trigrams\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assigning value to each word sequence to 1  (for every occurance of the  combo, (a,b), c : 1 the valube is one, sum all the possibilities and divided by the total occurance to get probabbility of the 3rd word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a placeholder for model\n",
    "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "\n",
    "for w1, w2, w3 in trigrams(tokens, pad_right=True, pad_left=True):\n",
    "    model[(w1, w2)][w3] += 1\n",
    "\n",
    "\n",
    "for w1_w2 in model:\n",
    "    total_count = float(sum(model[w1_w2].values()))\n",
    "    for w3 in model[w1_w2]:\n",
    "        model[w1_w2][w3] /= total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 0.5, 'it': 0.5}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model[\"i\", \"think\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'not': 0.5, 'being': 0.5}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model[\"we\", \"are\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ok': 0.3333333333333333,\n",
       " 'unlikely': 0.3333333333333333,\n",
       " 'easier': 0.3333333333333333}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model[\"it\", \"is\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'like': 0.5, 'say': 0.25, 'recommend': 0.25}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model[\"i\", \"would\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
